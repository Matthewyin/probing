"""
æ‰¹é‡è¯Šæ–­è¿è¡Œå™¨ - æ”¯æŒä»é…ç½®æ–‡ä»¶æ‰¹é‡æ‰§è¡Œç½‘ç»œè¯Šæ–­
"""
import asyncio
import json
import time
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

from .config_loader import ConfigLoader, GlobalSettings
from .diagnosis import DiagnosisRunner
from .models import NetworkDiagnosisResult, DiagnosisRequest, PublicIPInfo
from .logger import get_logger, setup_config_logging
from .services import PublicIPService
from .config import settings
from .resource_monitor import ResourceMonitor

logger = get_logger(__name__)


class BatchDiagnosisResult:
    """æ‰¹é‡è¯Šæ–­ç»“æœ"""
    
    def __init__(self):
        self.results: List[NetworkDiagnosisResult] = []
        self.start_time: datetime = datetime.now()
        self.end_time: Optional[datetime] = None
        self.total_time_ms: float = 0.0
        self.successful_count: int = 0
        self.failed_count: int = 0
        self.config_file: Optional[str] = None
    
    def add_result(self, result: NetworkDiagnosisResult):
        """æ·»åŠ å•ä¸ªè¯Šæ–­ç»“æœ"""
        self.results.append(result)
        if result.success:
            self.successful_count += 1
        else:
            self.failed_count += 1
    
    def finalize(self):
        """å®Œæˆæ‰¹é‡è¯Šæ–­ï¼Œè®¡ç®—æ€»æ—¶é—´"""
        self.end_time = datetime.now()
        self.total_time_ms = (self.end_time - self.start_time).total_seconds() * 1000
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–æ±‡æ€»ä¿¡æ¯"""
        if not self.results:
            return {}
        
        # è®¡ç®—æ€§èƒ½ç»Ÿè®¡
        response_times = [r.total_diagnosis_time_ms for r in self.results if r.success]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        # è®¡ç®—è¿æ¥ç»Ÿè®¡
        tcp_times = [r.tcp_connection.connect_time_ms for r in self.results 
                    if r.tcp_connection and r.tcp_connection.is_connected]
        avg_tcp_time = sum(tcp_times) / len(tcp_times) if tcp_times else 0
        
        # TLSç»Ÿè®¡
        tls_results = [r for r in self.results if r.tls_info and r.tls_info.is_secure]
        tls_protocols = {}
        for result in tls_results:
            protocol = result.tls_info.protocol_version
            tls_protocols[protocol] = tls_protocols.get(protocol, 0) + 1
        
        # HTTPçŠ¶æ€ç ç»Ÿè®¡
        http_status_codes = {}
        for result in self.results:
            if result.http_response:
                status = result.http_response.status_code
                http_status_codes[status] = http_status_codes.get(status, 0) + 1
        
        return {
            "execution_summary": {
                "total_targets": len(self.results),
                "successful": self.successful_count,
                "failed": self.failed_count,
                "success_rate": (self.successful_count / len(self.results)) * 100 if self.results else 0,
                "total_execution_time_ms": self.total_time_ms,
                "start_time": self.start_time.isoformat(),
                "end_time": self.end_time.isoformat() if self.end_time else None,
                "config_file": self.config_file
            },
            "performance_statistics": {
                "average_diagnosis_time_ms": avg_response_time,
                "average_tcp_connect_time_ms": avg_tcp_time,
                "fastest_diagnosis_ms": min(response_times) if response_times else 0,
                "slowest_diagnosis_ms": max(response_times) if response_times else 0
            },
            "security_statistics": {
                "tls_enabled_count": len(tls_results),
                "tls_protocols": tls_protocols,
                "secure_connections_rate": (len(tls_results) / len(self.results)) * 100 if self.results else 0
            },
            "http_statistics": {
                "status_codes": http_status_codes,
                "http_enabled_count": len([r for r in self.results if r.http_response])
            }
        }
    
    def to_json_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºJSONå­—å…¸"""
        return {
            "summary": self.get_summary(),
            "individual_results": [result.to_json_dict() for result in self.results]
        }


class BatchDiagnosisRunner:
    """æ‰¹é‡è¯Šæ–­è¿è¡Œå™¨"""
    
    def __init__(self, config_file: str = "input/targets.yaml"):
        self.config_file = config_file
        self.config_loader = ConfigLoader(config_file)

        # ç”ŸæˆåŸºäºé…ç½®æ–‡ä»¶çš„è¾“å‡ºå­ç›®å½•
        config_name = Path(config_file).stem  # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        self.config_name = config_name
        self.output_subdir = Path(settings.OUTPUT_DIR) / config_name

        # è®¾ç½®åŸºäºé…ç½®æ–‡ä»¶çš„æ—¥å¿—è®°å½•
        self.log_filepath = setup_config_logging(config_name)

        # åˆ›å»ºè¯Šæ–­è¿è¡Œå™¨ï¼Œä½¿ç”¨å­ç›®å½•ä½œä¸ºè¾“å‡ºç›®å½•
        self.diagnosis_runner = DiagnosisRunner(str(self.output_subdir))

        # åˆ›å»ºå…¬ç½‘IPæœåŠ¡
        self.public_ip_service = PublicIPService()
        self.public_ip_info: Optional[PublicIPInfo] = None
    
    async def run_batch_diagnosis(self) -> BatchDiagnosisResult:
        """æ‰§è¡Œæ‰¹é‡è¯Šæ–­"""
        logger.info(f"Starting batch diagnosis from config file: {self.config_file}")
        logger.info(f"Output directory: {self.output_subdir}")
        logger.info(f"Log file: {self.log_filepath}")

        # ğŸ” ç›‘æ§ï¼šè®°å½•å¼€å§‹æ—¶çš„èµ„æºçŠ¶æ€
        ResourceMonitor.log_status_summary()

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_subdir.mkdir(parents=True, exist_ok=True)

        # åŠ è½½é…ç½®
        try:
            config = self.config_loader.load_config()
            requests = self.config_loader.get_diagnosis_requests()
            global_settings = self.config_loader.get_global_settings()
        except Exception as e:
            logger.error(f"Failed to load configuration: {str(e)}")
            raise
        
        # åˆ›å»ºæ‰¹é‡ç»“æœå¯¹è±¡
        batch_result = BatchDiagnosisResult()
        batch_result.config_file = self.config_file
        
        logger.info(f"Loaded {len(requests)} targets for diagnosis")
        logger.info(f"Max concurrent: {global_settings.max_concurrent}")

        # è·å–å…¬ç½‘IPä¿¡æ¯ï¼ˆåœ¨è¯Šæ–­å¼€å§‹å‰è·å–ä¸€æ¬¡ï¼‰
        logger.info("Getting public IP information...")
        try:
            self.public_ip_info = await self.public_ip_service.get_public_ip_info()
            if self.public_ip_info:
                logger.info(f"Public IP: {self.public_ip_info.ip} ({self.public_ip_info.service_provider})")
                if self.public_ip_info.city and self.public_ip_info.isp:
                    logger.info(f"Location: {self.public_ip_info.city}, ISP: {self.public_ip_info.isp}")
            else:
                logger.warning("Failed to get public IP information")
        except Exception as e:
            logger.warning(f"Error getting public IP information: {e}")
            self.public_ip_info = None

        # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(global_settings.max_concurrent)
        
        # åˆ›å»ºè¯Šæ–­ä»»åŠ¡
        tasks = []
        for i, request in enumerate(requests):
            task = self._diagnose_with_semaphore(
                semaphore, request, i + 1, len(requests), global_settings
            )
            tasks.append(task)
        
        # æ‰§è¡Œæ‰€æœ‰è¯Šæ–­ä»»åŠ¡
        try:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†ç»“æœ
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"Target {i+1} failed with exception: {str(result)}")
                    # åˆ›å»ºä¸€ä¸ªå¤±è´¥çš„ç»“æœ
                    failed_result = NetworkDiagnosisResult(
                        domain=requests[i].domain,
                        total_diagnosis_time_ms=0.0,
                        success=False,
                        error_messages=[f"Exception: {str(result)}"],
                        public_ip_info=self.public_ip_info
                    )
                    batch_result.add_result(failed_result)
                else:
                    batch_result.add_result(result)
            
        except Exception as e:
            logger.error(f"Batch diagnosis failed: {str(e)}")
            raise
        
        # å®Œæˆæ‰¹é‡è¯Šæ–­
        batch_result.finalize()
        
        # ä¿å­˜ç»“æœ
        if global_settings.save_summary_report:
            await self._save_batch_report(batch_result, global_settings)
        
        logger.info(f"Batch diagnosis completed: {batch_result.successful_count}/{len(requests)} successful")

        # ğŸ” ç›‘æ§ï¼šè®°å½•ç»“æŸæ—¶çš„èµ„æºçŠ¶æ€
        ResourceMonitor.log_status_summary()

        return batch_result
    
    async def _diagnose_with_semaphore(
        self, 
        semaphore: asyncio.Semaphore, 
        request: DiagnosisRequest, 
        current: int, 
        total: int,
        global_settings: GlobalSettings
    ) -> NetworkDiagnosisResult:
        """ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶çš„è¯Šæ–­ä»»åŠ¡"""
        async with semaphore:
            # æ–¹æ¡ˆ3ï¼šæ”¹è¿›æ—¥å¿—æ˜¾ç¤º
            if request.url:
                logger.info(f"[{current}/{total}] Starting diagnosis for URL: {request.url}")
            else:
                logger.info(f"[{current}/{total}] Starting diagnosis for {request.domain}:{request.port}")
            
            try:
                # æ‰§è¡Œè¯Šæ–­
                result = await asyncio.wait_for(
                    self.diagnosis_runner.coordinator.diagnose(request),
                    timeout=global_settings.timeout_seconds
                )
                
                # æ·»åŠ å…¬ç½‘IPä¿¡æ¯åˆ°è¯Šæ–­ç»“æœ
                if self.public_ip_info:
                    result.public_ip_info = self.public_ip_info

                # ä¿å­˜å•ä¸ªæ–‡ä»¶
                if global_settings.save_individual_files:
                    self.diagnosis_runner.coordinator.save_result_to_file(result)

                status = "SUCCESS" if result.success else "FAILED"
                # æ–¹æ¡ˆ3ï¼šæ”¹è¿›æ—¥å¿—æ˜¾ç¤º
                if request.url:
                    logger.info(f"[{current}/{total}] {request.url} - {status} ({result.total_diagnosis_time_ms:.2f}ms)")
                else:
                    logger.info(f"[{current}/{total}] {request.domain}:{request.port} - {status} ({result.total_diagnosis_time_ms:.2f}ms)")

                return result
                
            except asyncio.TimeoutError:
                # æ–¹æ¡ˆ3ï¼šæ”¹è¿›é”™è¯¯æ—¥å¿—æ˜¾ç¤º
                if request.url:
                    logger.error(f"[{current}/{total}] {request.url} - TIMEOUT")
                else:
                    logger.error(f"[{current}/{total}] {request.domain}:{request.port} - TIMEOUT")
                timeout_result = NetworkDiagnosisResult(
                    domain=request.domain,
                    total_diagnosis_time_ms=global_settings.timeout_seconds * 1000,
                    success=False,
                    error_messages=[f"Diagnosis timeout after {global_settings.timeout_seconds} seconds"],
                    public_ip_info=self.public_ip_info
                )
                return timeout_result
            except Exception as e:
                # æ–¹æ¡ˆ3ï¼šæ”¹è¿›é”™è¯¯æ—¥å¿—æ˜¾ç¤º
                if request.url:
                    logger.error(f"[{current}/{total}] {request.url} - ERROR: {str(e)}")
                else:
                    logger.error(f"[{current}/{total}] {request.domain}:{request.port} - ERROR: {str(e)}")
                error_result = NetworkDiagnosisResult(
                    domain=request.domain,
                    total_diagnosis_time_ms=0.0,
                    success=False,
                    error_messages=[f"Diagnosis failed: {str(e)}"],
                    public_ip_info=self.public_ip_info
                )
                return error_result
    
    async def _save_batch_report(self, batch_result: BatchDiagnosisResult, global_settings: GlobalSettings):
        """ä¿å­˜æ‰¹é‡è¯Šæ–­æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"batch_diagnosis_report_{timestamp}.json"
        filepath = Path(settings.OUTPUT_DIR) / filename
        
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            filepath.parent.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜JSONæŠ¥å‘Š
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(batch_result.to_json_dict(), f, indent=2, ensure_ascii=False)
            
            logger.info(f"Batch diagnosis report saved to {filepath}")
            
            # å¦‚æœå¯ç”¨äº†åˆ†æåŠŸèƒ½ï¼Œç”Ÿæˆåˆ†ææŠ¥å‘Š
            if global_settings.include_performance_analysis or global_settings.include_security_analysis:
                await self._generate_analysis_report(batch_result, global_settings)
                
        except Exception as e:
            logger.error(f"Failed to save batch report: {str(e)}")
    
    async def _generate_analysis_report(self, batch_result: BatchDiagnosisResult, global_settings: GlobalSettings):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"analysis_report_{timestamp}.txt"
        filepath = Path(settings.OUTPUT_DIR) / filename
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write("ç½‘ç»œè¯Šæ–­åˆ†ææŠ¥å‘Š\n")
                f.write("=" * 50 + "\n\n")
                
                summary = batch_result.get_summary()
                
                # æ‰§è¡Œæ‘˜è¦
                exec_summary = summary["execution_summary"]
                f.write(f"æ‰§è¡Œæ‘˜è¦:\n")
                f.write(f"  æ€»ç›®æ ‡æ•°: {exec_summary['total_targets']}\n")
                f.write(f"  æˆåŠŸæ•°: {exec_summary['successful']}\n")
                f.write(f"  å¤±è´¥æ•°: {exec_summary['failed']}\n")
                f.write(f"  æˆåŠŸç‡: {exec_summary['success_rate']:.1f}%\n")
                f.write(f"  æ€»æ‰§è¡Œæ—¶é—´: {exec_summary['total_execution_time_ms']:.2f}ms\n\n")
                
                # æ€§èƒ½åˆ†æ
                if global_settings.include_performance_analysis:
                    perf_stats = summary["performance_statistics"]
                    f.write(f"æ€§èƒ½åˆ†æ:\n")
                    f.write(f"  å¹³å‡è¯Šæ–­æ—¶é—´: {perf_stats['average_diagnosis_time_ms']:.2f}ms\n")
                    f.write(f"  å¹³å‡TCPè¿æ¥æ—¶é—´: {perf_stats['average_tcp_connect_time_ms']:.2f}ms\n")
                    f.write(f"  æœ€å¿«è¯Šæ–­: {perf_stats['fastest_diagnosis_ms']:.2f}ms\n")
                    f.write(f"  æœ€æ…¢è¯Šæ–­: {perf_stats['slowest_diagnosis_ms']:.2f}ms\n\n")
                
                # å®‰å…¨åˆ†æ
                if global_settings.include_security_analysis:
                    sec_stats = summary["security_statistics"]
                    f.write(f"å®‰å…¨åˆ†æ:\n")
                    f.write(f"  å¯ç”¨TLSçš„è¿æ¥æ•°: {sec_stats['tls_enabled_count']}\n")
                    f.write(f"  å®‰å…¨è¿æ¥ç‡: {sec_stats['secure_connections_rate']:.1f}%\n")
                    f.write(f"  TLSåè®®åˆ†å¸ƒ:\n")
                    for protocol, count in sec_stats['tls_protocols'].items():
                        f.write(f"    {protocol}: {count}\n")
                    f.write("\n")
                
                # HTTPçŠ¶æ€ç åˆ†æ
                http_stats = summary["http_statistics"]
                f.write(f"HTTPçŠ¶æ€ç åˆ†å¸ƒ:\n")
                for status_code, count in http_stats['status_codes'].items():
                    f.write(f"  {status_code}: {count}\n")
            
            logger.info(f"Analysis report saved to {filepath}")
            
        except Exception as e:
            logger.error(f"Failed to generate analysis report: {str(e)}")


async def run_batch_from_config(config_file: str = "input/targets.yaml") -> BatchDiagnosisResult:
    """ä¾¿æ·å‡½æ•°ï¼šä»é…ç½®æ–‡ä»¶è¿è¡Œæ‰¹é‡è¯Šæ–­"""
    runner = BatchDiagnosisRunner(config_file)
    return await runner.run_batch_diagnosis()
